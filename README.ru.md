# Планировщик задач

[![CI](https://github.com/buharov-alexander/job-scheduler/actions/workflows/ci.yml/badge.svg)](https://github.com/buharov-alexander/job-scheduler/actions/workflows/ci.yml)

[English version](README.md)

## Описание проекта

Этот проект реализует распределённый планировщик задач (Job Scheduler) для учебных и демонстрационных целей. Основная задача — предоставить API для постановки задач на выполнение в определённое время, обеспечить надёжное хранение и корректную обработку задач в многосервисной архитектуре.

## Архитектура и взаимодействие сервисов

В систему входят следующие основные сервисы:

- **API-сервис** — принимает запросы от пользователей для создания и мониторинга задач, сохраняет информацию о задачах в базу данных.
- **Task Runner (исполнитель задач)** — периодически выбирает задачи, время запуска которых наступило, и инициирует их выполнение, отправляя сообщения в Kafka.
- **Execution Service (исполнитель задач)** — получает задачи из Kafka и выполняет их, после чего обновляет статус задачи.

### Схема взаимодействия

1. Пользователь создаёт задачу через API-сервис.
2. API-сервис сохраняет задачу со всей необходимой метаинформацией (время исполнения, имя задачи) в базе данных.
3. Task Runner сервис раз в минуту ищет задачи для исполнения и отправляет их идентификаторы через Kafka.
4. Execution Service получает задачи из Kafka, исполняет их и обновляет статус.

<img width="719" alt="Screenshot 2024-10-27 at 23 17 27" src="https://github.com/user-attachments/assets/d866514e-6a13-413e-ae93-46a3a9b36b86">

## Важные детали реализации

- **Хранение задач в базе данных** — все задачи и их статусы сохраняются в реляционной БД, что позволяет обеспечить надёжность и восстановление после сбоев.
- **Выборка задач с помощью `SELECT FOR UPDATE SKIP LOCKED`** — Task Runner использует атомарную выборку и блокировку задач для выполнения, чтобы несколько инстансов сервиса не обработали одну и ту же задачу.
- **Передача задач через Kafka** — для масштабирования и отказоустойчивости задачи для исполнения передаются между сервисами с помощью Kafka, что позволяет разнести нагрузку и обеспечить гарантированную доставку.
- **Распределять задачи по партициям Kafka** — задачи распределяются по партициям, что позволяет равномерно загружать несколько инстансов Execution Service.
- **Мониторинг и метрики** — все сервисы интегрированы с Prometheus и Grafana для сбора метрик и мониторинга состояния системы.

Данный проект иллюстрирует типовые подходы к построению надёжного и масштабируемого планировщика задач с использованием популярных инструментов (Spring, Kafka, реляционная БД) и учётом типовых ошибок распределённых систем.

## Быстрый запуск через docker-compose

Для быстрого запуска всей системы используйте Docker Compose.

Запустить все сервисы:
 - АПИ-сервис
 - Сервис исполнителя задач (Task Runner)
 - Два сервиса выполнения задач (Execution Service)
 - База данных PostgreSQL
 - Kafka
 - Сервисы мониторинга (Prometheus, Grafana, Promtail, Loki, Kafka UI)
```
docker compose --profile all up --scale execution-service=2
```

### Swagger UI

Интерфейс Swagger для тестирования API доступен по адресу:
```
http://localhost:8081/swagger-ui.html
```

### Kafka UI

Веб-интерфейс для мониторинга Kafka:
```
http://localhost:8088/
```

### Grafana

Мониторинг и дашборды:
```
http://localhost:3000/
```
<img width="1725" height="856" alt="Screenshot 2026-01-03 at 19 12 02" src="https://github.com/user-attachments/assets/7174f6b4-18cb-45a6-ab19-54d93a0bff9a" />

